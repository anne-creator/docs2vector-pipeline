# ============================================================================
# Storage Configuration
# ============================================================================

# Storage mode for pipeline data:
# - "local": Store data only in local data/ directory (default, no cloud needed)
# - "s3": Store data in AWS S3 (requires S3 credentials below)
# - "auto": Use S3 if configured, otherwise local (smart fallback)
STORAGE_MODE=auto

# Pipeline processing mode:
# - "batch": Wait for all scraping to complete, then process sequentially (traditional)
# - "streaming": Process items as they're scraped for true concurrent execution (FASTER!)
#   Streaming mode benefits:
#   ✅ Stages overlap - much faster total time
#   ✅ Progress visibility - see results as they arrive
#   ✅ Better resource utilization - CPU working while scraper waits
PIPELINE_MODE=streaming

# ============================================================================
# Neo4j Configuration (OPTIONAL - Disabled by Default)
# ============================================================================

# Enable Neo4j vector database integration
# Set to "true" to enable Neo4j storage (Stage 5 of pipeline)
# Set to "false" to skip Neo4j and only use local/S3 storage
USE_NEO4J=false

# Neo4j credentials (only required if USE_NEO4J=true)
# NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
# NEO4J_USERNAME=neo4j
# NEO4J_PASSWORD=your-password-here
# NEO4J_DATABASE=neo4j

# ============================================================================
# AWS S3 Configuration (Optional - for cloud storage)
# ============================================================================

# S3 bucket name for storing pipeline data
S3_BUCKET_NAME=

# AWS credentials (leave empty to use local storage only)
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_REGION=us-east-1

# ============================================================================
# Embedding Configuration
# ============================================================================

# Choose your embedding provider:
# - "sentence-transformers" (local, no API key needed) - RECOMMENDED FOR DEVELOPMENT
# - "ollama" (local Ollama server, no API key needed)
# - "openai" (OpenAI API or compatible service)
EMBEDDING_PROVIDER=sentence-transformers

# ============================================================================
# Option 1: Sentence Transformers (Local) - DEFAULT
# ============================================================================
# Models: 
# - BAAI/bge-small-en-v1.5 (384-dim, high quality) - RECOMMENDED
# - all-MiniLM-L6-v2 (384-dim, fast)
# - all-mpnet-base-v2 (768-dim, quality)
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_BATCH_SIZE=32

# ============================================================================
# Option 2: Ollama (Local Server)
# ============================================================================
# Uncomment to use Ollama:
# EMBEDDING_PROVIDER=ollama
# EMBEDDING_MODEL=nomic-embed-text
# OLLAMA_BASE_URL=http://localhost:11434
# EMBEDDING_BATCH_SIZE=16

# ============================================================================
# Option 3: OpenAI-Compatible API
# ============================================================================
# Uncomment to use OpenAI or compatible APIs:
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_API_KEY=your-api-key-here
# OPENAI_API_BASE=https://api.openai.com/v1
# OPENAI_ORG_ID=  # Optional
# EMBEDDING_BATCH_SIZE=100

# Custom dimension override (optional, auto-detected if not set)
# EMBEDDING_DIMENSION=

# ============================================================================
# Pipeline Configuration
# ============================================================================
DATA_DIR=data
LOG_LEVEL=INFO

# ============================================================================
# Scraper Configuration
# ============================================================================
SCRAPER_DOWNLOAD_DELAY=1.0
SCRAPER_CONCURRENT_REQUESTS=2
SCRAPER_DEPTH_LIMIT=4

# ============================================================================
# Chunking Configuration
# ============================================================================
CHUNK_SIZE=512
CHUNK_OVERLAP=64

